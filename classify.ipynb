{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7955897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'id', 'width', 'height', 'license', 'flickr_url', 'coco_url', 'date_captured', 'gps', 'city_name', 'scene_description', 'video_info.frame_id', 'video_info.seq_id', 'video_info.vid_id', 'scene_level_tags.daytime', 'scene_level_tags.scene_environment', 'scene_level_tags.travel_alteration', 'scene_level_tags.weather', 'label'],\n",
      "        num_rows: 6251\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'id', 'width', 'height', 'license', 'flickr_url', 'coco_url', 'date_captured', 'gps', 'city_name', 'scene_description', 'video_info.frame_id', 'video_info.seq_id', 'video_info.vid_id', 'scene_level_tags.daytime', 'scene_level_tags.scene_environment', 'scene_level_tags.travel_alteration', 'scene_level_tags.weather', 'label'],\n",
      "        num_rows: 2298\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tải bộ dữ liệu từ Hugging Face Hub\n",
    "dataset = load_dataset(\"natix-network-org/roadwork\")\n",
    "train_ds = dataset[\"train\"]\n",
    "test_ds = dataset[\"test\"]\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856cf114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\n\\n# Duyệt và lấy mỗi lớp 1 ảnh đầu tiên\\nsample_label_0 = next(sample for sample in train_ds if sample[\"label\"] == 0)\\nsample_label_1 = next(sample for sample in train_ds if sample[\"label\"] == 1)\\n\\n# Hiển thị ảnh có label = 0\\nprint(\"Ảnh mẫu thuộc lớp 0:\")\\nplt.imshow(sample_label_0[\"image\"])\\nplt.axis(\"off\")\\nplt.title(\"Label 0\")\\nplt.show()\\n\\n# Hiển thị ảnh có label = 1\\nprint(\"Ảnh mẫu thuộc lớp 1:\")\\nplt.imshow(sample_label_1[\"image\"])\\nplt.axis(\"off\")\\nplt.title(\"Label 1\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Duyệt và lấy mỗi lớp 1 ảnh đầu tiên\n",
    "sample_label_0 = next(sample for sample in train_ds if sample[\"label\"] == 0)\n",
    "sample_label_1 = next(sample for sample in train_ds if sample[\"label\"] == 1)\n",
    "\n",
    "# Hiển thị ảnh có label = 0\n",
    "print(\"Ảnh mẫu thuộc lớp 0:\")\n",
    "plt.imshow(sample_label_0[\"image\"])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Label 0\")\n",
    "plt.show()\n",
    "\n",
    "# Hiển thị ảnh có label = 1\n",
    "print(\"Ảnh mẫu thuộc lớp 1:\")\n",
    "plt.imshow(sample_label_1[\"image\"])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Label 1\")\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c55b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Phân phối nhãn ban đầu: Counter({1: 5031, 0: 1220})\n",
      "✅ Cần tạo thêm 3811 ảnh cho lớp 0\n",
      "✅ Đã tạo 1220 ảnh augment.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from datasets import Dataset\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 📊 Đếm nhãn\n",
    "train_labels = [ex[\"label\"] for ex in train_ds]\n",
    "train_counts = Counter(train_labels)\n",
    "print(\"📊 Phân phối nhãn ban đầu:\", train_counts)\n",
    "\n",
    "# 🔍 Thông tin lớp thiểu số\n",
    "minority_label = min(train_counts, key=train_counts.get)\n",
    "majority_count = max(train_counts.values())\n",
    "minority_count = train_counts[minority_label]\n",
    "num_to_generate = majority_count - minority_count\n",
    "print(f\"✅ Cần tạo thêm {num_to_generate} ảnh cho lớp {minority_label}\")\n",
    "\n",
    "# 📦 Tạo transform augment\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "])\n",
    "\n",
    "# 🌀 Tạo ảnh augment từng bước (tránh giữ tất cả ảnh gốc trong RAM)\n",
    "augmented_data = []\n",
    "generated = 0\n",
    "\n",
    "for ex in train_ds:\n",
    "    if ex[\"label\"] == minority_label:\n",
    "        img = ex[\"image\"]\n",
    "        if not isinstance(img, Image.Image):\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "        aug_img = augment_transform(img)\n",
    "        augmented_data.append({\"image\": aug_img, \"label\": minority_label})\n",
    "        generated += 1\n",
    "\n",
    "        if generated >= num_to_generate:\n",
    "            break\n",
    "\n",
    "print(f\"✅ Đã tạo {len(augmented_data)} ảnh augment.\")\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "# Tạo Dataset từ augmented_data\n",
    "aug_ds = Dataset.from_list(augmented_data)\n",
    "\n",
    "# Nối 2 dataset mà không cần load vào RAM\n",
    "train_ds = concatenate_datasets([train_ds, aug_ds])\n",
    "\n",
    "# ✅ Đã tạo {len(augmented_data)} ảnh augment.\n",
    "from datasets import concatenate_datasets\n",
    "\n",
    "# 🔁 Gộp lại dùng concatenate_datasets (tránh MemoryError)\n",
    "aug_ds = Dataset.from_list(augmented_data)\n",
    "train_ds = concatenate_datasets([train_ds, aug_ds])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc2f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# đặt tên cho các lớp\n",
    "label_names = {\n",
    "    0: \"No Roadwork\",\n",
    "    1: \"Roadwork\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10877eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8691/8691 [10:27<00:00, 13.86 examples/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "from torchvision import transforms\n",
    "\n",
    "# Dùng processor tương ứng với mô hình ViT\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "\n",
    "# Hàm tiền xử lý toàn bộ batch\n",
    "def preprocess(batch):\n",
    "    images = [img.resize((224, 224)) for img in batch[\"image\"]]\n",
    "    encoding = processor(images, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"pixel_values\": encoding[\"pixel_values\"],\n",
    "        \"labels\": batch[\"label\"]\n",
    "    }\n",
    "\n",
    "# Tiền xử lý tập huấn luyện và kiểm tra với batch_size nhỏ để tránh MemoryError\n",
    "train_ds = train_ds.map(preprocess, batched=True, batch_size=16, remove_columns=[\"image\"])\n",
    "test_ds = test_ds.map(preprocess, batched=True, batch_size=16, remove_columns=[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3c3373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nfrom collections import Counter\\nimport torch\\n\\n# 🛠 Dummy transform không làm gì cả\\ndef no_transform(example):\\n    return example\\n\\n# 🔁 Gán tạm transform \"trống\"\\ntrain_ds.set_transform(no_transform)\\ntest_ds.set_transform(no_transform)\\n\\n# ✅ Lấy nhãn an toàn\\ntrain_labels = [example[\"label\"] for example in train_ds]\\ntest_labels = [example[\"label\"] for example in test_ds]\\n\\n# ✅ Gán lại transform gốc\\ntrain_ds.set_transform(transform)\\ntest_ds.set_transform(transform)\\n\\n# 📊 Đếm số lượng lớp\\ntrain_counts = Counter(train_labels)\\ntest_counts = Counter(test_labels)\\n\\nprint(\"📊 Phân phối nhãn train:\", train_counts)\\nprint(\"📊 Phân phối nhãn test:\", test_counts)\\n\\n# ⚖️ Tính class weights\\ntotal = sum(train_counts.values())\\nclass_weights = [total / train_counts[i] for i in sorted(train_counts.keys())]\\nclass_weights = torch.tensor(class_weights, dtype=torch.float)\\n\\n# ⚙️ Dùng CPU\\ndevice = torch.device(\"cpu\")\\nclass_weights = class_weights.to(device)\\n\\nprint(\"✅ class_weights =\", class_weights)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# 🛠 Dummy transform không làm gì cả\n",
    "def no_transform(example):\n",
    "    return example\n",
    "\n",
    "# 🔁 Gán tạm transform \"trống\"\n",
    "train_ds.set_transform(no_transform)\n",
    "test_ds.set_transform(no_transform)\n",
    "\n",
    "# ✅ Lấy nhãn an toàn\n",
    "train_labels = [example[\"label\"] for example in train_ds]\n",
    "test_labels = [example[\"label\"] for example in test_ds]\n",
    "\n",
    "# ✅ Gán lại transform gốc\n",
    "train_ds.set_transform(transform)\n",
    "test_ds.set_transform(transform)\n",
    "\n",
    "# 📊 Đếm số lượng lớp\n",
    "train_counts = Counter(train_labels)\n",
    "test_counts = Counter(test_labels)\n",
    "\n",
    "print(\"📊 Phân phối nhãn train:\", train_counts)\n",
    "print(\"📊 Phân phối nhãn test:\", test_counts)\n",
    "\n",
    "# ⚖️ Tính class weights\n",
    "total = sum(train_counts.values())\n",
    "class_weights = [total / train_counts[i] for i in sorted(train_counts.keys())]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# ⚙️ Dùng CPU\n",
    "device = torch.device(\"cpu\")\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(\"✅ class_weights =\", class_weights)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd8a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"No Roadwork\", 1: \"Roadwork\"},\n",
    "    label2id={\"No Roadwork\": 0, \"Roadwork\": 1},\n",
    "    ignore_mismatched_sizes=True  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03fb8ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from transformers import AutoModelForImageClassification\\n\\nmodel = AutoModelForImageClassification.from_pretrained(\\n    \"google/vit-base-patch16-224\",\\n    num_labels=2,  # Vì có 2 lớp\\n    id2label=label_names,  # Đặt lại tên lớp cho đẹp\\n    label2id={v: k for k, v in label_names.items()},\\n    ignore_mismatched_sizes=True  # Cho phép thay đổi output layer\\n)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from transformers import AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224\",\n",
    "    num_labels=2,  # Vì có 2 lớp\n",
    "    id2label=label_names,  # Đặt lại tên lớp cho đẹp\n",
    "    label2id={v: k for k, v in label_names.items()},\n",
    "    ignore_mismatched_sizes=True  # Cho phép thay đổi output layer\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713e29e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",  # Đúng với transformers >= 4.0.0\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf5aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9fff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3001' max='3261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3001/3261 2:26:04 < 12:39, 0.34 it/s, Epoch 2.76/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.127344</td>\n",
       "      <td>0.965187</td>\n",
       "      <td>0.962241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.152190</td>\n",
       "      <td>0.965622</td>\n",
       "      <td>0.962760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.121565</td>\n",
       "      <td>0.969974</td>\n",
       "      <td>0.969772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.140679</td>\n",
       "      <td>0.966057</td>\n",
       "      <td>0.965662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.147602</td>\n",
       "      <td>0.970844</td>\n",
       "      <td>0.969527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/288 02:31 < 04:47, 0.65 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "def custom_data_collator(features):\n",
    "    for feature in features:\n",
    "        feature.pop(\"id\", None)  # loại bỏ id\n",
    "    return default_data_collator(features)\n",
    "\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "# Đảm bảo chỉ giữ lại các cột cần thiết (pixel_values, labels)\n",
    "training_args.remove_unused_columns = True\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=custom_data_collator  # <<< sửa ở đây\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Dự đoán trên tập test (hoặc validation)\n",
    "predictions = trainer.predict(test_ds)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Tính confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Vẽ confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c372968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, ViTForImageClassification\n",
    "\n",
    "# Load mô hình và processor\n",
    "# Nếu đã fine-tune xong rồi thì dùng dòng này để load lại:\n",
    "# model = ViTForImageClassification.from_pretrained(\"output_model\")\n",
    "# processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Thiết bị tính toán\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Ảnh người dùng\n",
    "image_path = r\"C:\\Users\\admin\\Documents\\tlh\\ielts\\task 1\\test1.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image.show()\n",
    "\n",
    "# Tiền xử lý và đưa lên đúng thiết bị\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Dự đoán\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# In kết quả\n",
    "label = model.config.id2label[predicted_class]\n",
    "print(f\"Ảnh dự đoán thuộc lớp: {predicted_class} - {label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
